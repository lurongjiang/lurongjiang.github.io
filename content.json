{"meta":{"title":"Blog","subtitle":"个人博客,记录成长历程","description":"个人博客,记录成长历程","author":"LRJ","url":"http://yoursite.com","root":"/"},"pages":[],"posts":[{"title":"Hive UDF","slug":"Hive UDF","date":"2019-03-15T03:19:04.000Z","updated":"2020-02-19T04:23:48.241Z","comments":true,"path":"2019/03/15/Hive UDF/","link":"","permalink":"http://yoursite.com/2019/03/15/Hive%20UDF/","excerpt":"","text":"Hive UDFhive内置函数并不一定满足我们的业务要求,所以需要拓展,即用户自定义函数 UDF User Defined Function UDF (one-to-one) UDAF(many-to-one) UDTF(one-to-many) 创建UDF步骤 添加依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.hive&lt;/groupId&gt; &lt;artifactId&gt;hive-exec&lt;/artifactId&gt; &lt;version&gt;$&#123;hive.cdh.version&#125;&lt;/version&gt;&lt;/dependency&gt; 创建自定义类,继承UDF","categories":[{"name":"Hive","slug":"Hive","permalink":"http://yoursite.com/categories/Hive/"}],"tags":[{"name":"hive","slug":"hive","permalink":"http://yoursite.com/tags/hive/"},{"name":"udf","slug":"udf","permalink":"http://yoursite.com/tags/udf/"},{"name":"user-defined-function","slug":"user-defined-function","permalink":"http://yoursite.com/tags/user-defined-function/"}]},{"title":"Hadoop MapReduce编程核心","slug":"Hadoop MapReduce编程核心","date":"2019-03-12T07:14:04.000Z","updated":"2020-02-19T04:23:19.987Z","comments":true,"path":"2019/03/12/Hadoop MapReduce编程核心/","link":"","permalink":"http://yoursite.com/2019/03/12/Hadoop%20MapReduce%E7%BC%96%E7%A8%8B%E6%A0%B8%E5%BF%83/","excerpt":"","text":"Hadoop MapReduce编程核心Partitioner 分区1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * Partitions the key space. * * &lt;p&gt;&lt;code&gt;Partitioner&lt;/code&gt; controls the partitioning of the keys of the * intermediate map-outputs. The key (or a subset of the key) is used to derive * the partition, typically by a hash function. The total number of partitions * is the same as the number of reduce tasks for the job. Hence this controls * which of the &lt;code&gt;m&lt;/code&gt; reduce tasks the intermediate key (and hence the * record) is sent for reduction.&lt;/p&gt; * partitioner是控制中间map阶段输出结果的key的分区.key通常被hash,分发到各个分区 * 分区数一般和reduce job的个数相等, * @see Reducer */@InterfaceAudience.Public@InterfaceStability.Stablepublic interface Partitioner&lt;K2, V2&gt; extends JobConfigurable &#123; /** * Get the paritition number for a given key (hence record) given the total * number of partitions i.e. number of reduce-tasks for the job. * * &lt;p&gt;Typically a hash function on a all or a subset of the key.&lt;/p&gt; * 根据分区总数,例如reduce job个数,获取分区的编号.一般是对所有key或者key的一部分进行进行hash处理 * @param key the key to be paritioned. * @param value the entry value. * @param numPartitions the total number of partitions. * @return the partition number for the &lt;code&gt;key&lt;/code&gt;. */ int getPartition(K2 key, V2 value, int numPartitions);&#125;/*** hash分区的实现就是key取hashCode和reduce个数进行取模*/public class HashPartitioner&lt;K2, V2&gt; implements Partitioner&lt;K2, V2&gt; &#123; public void configure(JobConf job) &#123;&#125; /** Use &#123;@link Object#hashCode()&#125; to partition. */ public int getPartition(K2 key, V2 value, int numReduceTasks) &#123; return (key.hashCode() &amp; Integer.MAX_VALUE) % numReduceTasks; &#125;&#125; 需要注意的是 分区数一般和reduce job个数相等 如果分区数&lt;reduce job个数,将导致输出有很多无用的空文件 如果分区数&gt;reduce job个数,将导致有些map输出找不到hash路径,出现java.io.IOException: Illegal partition for xxx的异常 Combiner 局部汇总Combiner是hadoop对map阶段输出结果进行本地局部聚合,提高后面reduce的效率,避免大量数据进行网络传输. 需要注意的是 并非所有的任务都适用于Combiner 求和等操作,局部聚合可以有效的提高后面reduce的效率 平均值等操作,这种并不适用,因为局部平均值和全局平均值还是有差异的","categories":[{"name":"Hadoop","slug":"Hadoop","permalink":"http://yoursite.com/categories/Hadoop/"}],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://yoursite.com/tags/hadoop/"},{"name":"MapReduce","slug":"MapReduce","permalink":"http://yoursite.com/tags/MapReduce/"}]}]}