<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>SpringCloud概述</title>
      <link href="/2019/04/05/SpringCloud/"/>
      <url>/2019/04/05/SpringCloud/</url>
      
        <content type="html"><![CDATA[        <h1   id="SpringCloud" >          <span class="heading-link">SpringCloud</span>        </h1>              <h2   id="SpringCloud概述" >          <span class="heading-link">SpringCloud概述</span>        </h2>              <h3   id="官网" >          <span class="heading-link">官网</span>        </h3>      <ul><li><span class="external-link"><a   href="https://spring.io/projects/spring-cloud"  target="_blank" rel="noopener">官网</a><i class="fa fa-external-link"></i></span></li></ul>        <h3   id="主要功能" >          <span class="heading-link">主要功能</span>        </h3>      <p><img src="image/image-20200207192330288.png" alt="image-20200207192330288"></p>        <h3   id="常用子项目" >          <span class="heading-link">常用子项目</span>        </h3>      <p><img src="image/image-20200207192553245.png" alt="image-20200207192553245"></p>        <h3   id="版本与兼容" >          <span class="heading-link">版本与兼容</span>        </h3>      <ul><li><p>SpringCloud的版本命名</p><ul><li><p><strong>版本命名</strong></p><p>SpringCloud的版本,前半部分(如Hoxton,Greenwich),意思是发布列车(ReleaseTrain),以伦敦地铁的站名命名,因为SpringCloud有很多的子项目,每个项目都有自己的版本管理,按照发布顺序以A,B,C等为首字母依次命名,已经发布的版本顺序为:</p></li></ul><p><code>Angel -&gt; Brixton -&gt; Camden -&gt; Dalston -&gt; Edgware -&gt; Finchley -&gt; Greenwich -&gt; Hoxton</code><br><img src="C:%5CUsers%5C18179%5CPictures%5Clondontuberail-1.png" alt="londontuberail-1"></p><p>后半部分(如SR,SR1,SR2),意思是服务发布(ServiceRelease),即重大Bug修复</p><ul><li><strong>版本发布流程</strong></li></ul><p><code>SNAPSHOT -&gt; Mx -&gt; RELEASE -&gt; SRx</code>,其中x就是一些数字序号,例如M1,M2,SR1,SR2.SNAPSHOT为快照版本(开发版本),Mx为里程碑版本,此时并不是正式版本,但是已经接近正式版,经过多个版本迭代之后,发布第一个RELEASE版本,正式版本;在RELEASE版本之后如果有重大bug修复就会发布SR版本</p></li></ul><div class="table-container"><table><thead><tr><th>Hoxton SR1 <strong>CURRENT</strong> <strong>GA</strong></th><th><span class="external-link"><a   href="https://cloud.spring.io/spring-cloud-static/Hoxton.SR1/reference/html/spring-cloud.html"  target="_blank" rel="noopener"> Reference Doc.</a><i class="fa fa-external-link"></i></span></th></tr></thead><tbody><tr><td>Hoxton <strong>SNAPSHOT</strong></td><td><span class="external-link"><a   href="https://spring.io/projects/spring-cloud"  target="_blank" rel="noopener"> Reference Doc.</a><i class="fa fa-external-link"></i></span></td></tr><tr><td>Greenwich SR5 <strong>GA</strong></td><td><span class="external-link"><a   href="https://cloud.spring.io/spring-cloud-static/Greenwich.SR5/"  target="_blank" rel="noopener"> Reference Doc.</a><i class="fa fa-external-link"></i></span></td></tr><tr><td>Greenwich <strong>SNAPSHOT</strong></td><td><span class="external-link"><a   href="https://spring.io/projects/spring-cloud"  target="_blank" rel="noopener"> Reference Doc.</a><i class="fa fa-external-link"></i></span></td></tr></tbody></table></div><hr><ul><li><p>SpringCloud的版本生命周期</p><ul><li><p><strong>版本发布规划</strong></p><p><span class="external-link"><a   href="https://github.com/spring-cloud/spring-cloud-release/milestones"  target="_blank" rel="noopener">https://github.com/spring-cloud/spring-cloud-release/milestones</a><i class="fa fa-external-link"></i></span></p></li><li><p><strong>版本发布记录</strong></p><p><span class="external-link"><a   href="https://github.com/spring-cloud/spring-cloud-release/releases"  target="_blank" rel="noopener">https://github.com/spring-cloud/spring-cloud-release/releases</a><i class="fa fa-external-link"></i></span></p></li><li><p><strong>版本终止声明</strong></p><p><span class="external-link"><a   href="https://spring.io/projects/spring-cloud#overview"  target="_blank" rel="noopener">https://spring.io/projects/spring-cloud#overview</a><i class="fa fa-external-link"></i></span></p></li></ul></li><li><p>SpringBoot与SpringCloud的兼容性</p><ul><li>版本兼容性非常重要<br><span class="external-link"><a   href="https://spring.io/projects/spring-cloud#overview"  target="_blank" rel="noopener">https://spring.io/projects/spring-cloud#overview</a><i class="fa fa-external-link"></i></span></li></ul></li></ul><div class="table-container"><table><thead><tr><th>Release Train</th><th>Boot Version</th></tr></thead><tbody><tr><td>Hoxton</td><td>2.2.x</td></tr><tr><td>Greenwich</td><td>2.1.x</td></tr><tr><td>Finchley</td><td>2.0.x</td></tr><tr><td>Edgware</td><td>1.5.x</td></tr><tr><td>Dalston</td><td>1.5.x</td></tr></tbody></table></div><ul><li>生产环境如何选择选择<ul><li>坚决不适用非稳定版本</li><li>坚决不适用end-of-life版本</li><li>尽量使用最新版本<ul><li>RELEASE版本可以观望/调研,因为是第一个正式版,并没有在生产上得以广泛应用</li><li>SR2之后可以大规模使用</li></ul></li></ul></li></ul>        <h3   id="版本选择" >          <span class="heading-link">版本选择</span>        </h3>      <ul><li>SpringCloud Hoxton SR1</li><li>SpringBoot 2.2.4.RELEASE</li></ul><figure class="highlight xml"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">parent</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-parent<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.2.4.RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">relativePath</span>/&gt;</span> <span class="comment">&lt;!-- lookup parent from repository --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">parent</span>&gt;</span> </span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependencyManagement</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-dependencies --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-dependencies<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>Hoxton.SR1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">type</span>&gt;</span>pom<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">scope</span>&gt;</span>import<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencyManagement</span>&gt;</span></span><br></pre></td></tr></table></div></figure><p>检查项目是否能运行</p><figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mvn clean install -U</span><br></pre></td></tr></table></div></figure>        <h2   id="SpringCloud服务注册与发现" >          <span class="heading-link">SpringCloud服务注册与发现</span>        </h2>      <ul><li>使得服务消费者总能找到服务提供者</li></ul>        <h3   id="Consul单机版安装" >          <span class="heading-link">Consul单机版安装</span>        </h3>              <h4   id="Consul下载" >          <span class="heading-link">Consul下载</span>        </h4>      <ul><li>下载Consoule <span class="external-link"><a   href="https://releases.hashicorp.com/consul/1.6.3/consul_1.6.3_linux_amd64.zip"  target="_blank" rel="noopener">https://releases.hashicorp.com/consul/1.6.3/consul_1.6.3_linux_amd64.zip</a><i class="fa fa-external-link"></i></span></li></ul>        <h4   id="需要的端口" >          <span class="heading-link">需要的端口</span>        </h4>      <div class="table-container"><table><thead><tr><th align="left">Use</th><th align="left">Default Ports</th></tr></thead><tbody><tr><td align="left">DNS: The DNS server (TCP and UDP)</td><td align="left">8600</td></tr><tr><td align="left">HTTP: The HTTP API (TCP Only)</td><td align="left">8500</td></tr><tr><td align="left">HTTPS: The HTTPs API</td><td align="left">disabled (8501)*</td></tr><tr><td align="left">gRPC: The gRPC API</td><td align="left">disabled (8502)*</td></tr><tr><td align="left">LAN Serf: The Serf LAN port (TCP and UDP)</td><td align="left">8301</td></tr><tr><td align="left">Wan Serf: The Serf WAN port TCP and UDP)</td><td align="left">8302</td></tr><tr><td align="left">server: Server RPC address (TCP Only)</td><td align="left">8300</td></tr><tr><td align="left">Sidecar Proxy Min: Inclusive min port number to use for automatically assigned sidecar service registrations.</td><td align="left">21000</td></tr><tr><td align="left">Sidecar Proxy Max: Inclusive max port number to use for automatically assigned sidecar service registrations.</td><td align="left">21255</td></tr></tbody></table></div><p>检查端口是否被占用的方法</p><figure class="highlight shell"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Windows:</span><br><span class="line"><span class="meta">#</span><span class="bash"> 如果没有结果说明没有被占用</span></span><br><span class="line">netstat -ano| findstr "8500"</span><br><span class="line"></span><br><span class="line">Linux:</span><br><span class="line"><span class="meta">#</span><span class="bash"> 如果没有结果说明没有被占用</span></span><br><span class="line">netstat -antp |grep 8500</span><br><span class="line"></span><br><span class="line">macOS:</span><br><span class="line"><span class="meta">#</span><span class="bash"> 如果没有结果说明没有被占用</span></span><br><span class="line">netstat -ant | grep 8500</span><br><span class="line">或</span><br><span class="line">lsof -i:8500</span><br></pre></td></tr></table></div></figure>        <h4   id="安装和启动" >          <span class="heading-link">安装和启动</span>        </h4>      <ul><li>解压</li></ul><figure class="highlight shell"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./consul agent -dev -client 0.0.0.0</span><br></pre></td></tr></table></div></figure><ul><li>严重是否成功</li></ul><figure class="highlight shell"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./consul -v</span><br></pre></td></tr></table></div></figure><ul><li>访问Consul首页<code>localhost:8500</code></li></ul><p><strong>启动参数</strong></p><ul><li>-ui 开启ui</li><li>-client 让consul拥有client功能,接受服务注册;0.0.0.0允许任意ip注册,不写只能使用localhost连接</li><li>-dev 以开发模式运行consul</li></ul>        <h3   id="整合Consul" >          <span class="heading-link">整合Consul</span>        </h3>      <ul><li><p>添加依赖</p><figure class="highlight xml"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-starter-consul-discovery<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></div></figure></li></ul><ul><li><p>配置</p><figure class="highlight yml"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line"> <span class="attr">application:</span></span><br><span class="line">    <span class="comment"># 指定注册到consul的服务名称,分隔符不能是下划线</span></span><br><span class="line">    <span class="comment"># 如果服务发现组件是Consul,会强制转换成中划线,导致找不到服务</span></span><br><span class="line">    <span class="comment"># 如果服务发现组件是Ribbon,则因为Ribbon的问题(把默认名称当初虚拟主机名,而虚拟主机名不能用下划线),会造成微服务之间无法调用</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">micro-service-user</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">cloud:</span></span><br><span class="line">    <span class="attr">consul:</span></span><br><span class="line">      <span class="attr">host:</span> <span class="number">192.168</span><span class="number">.238</span><span class="number">.128</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">8500</span></span><br></pre></td></tr></table></div></figure></li><li><p>启动,检查consul ui的服务上线情况</p></li></ul>        <h3   id="Consul健康检查" >          <span class="heading-link">Consul健康检查</span>        </h3>      <p><img src="image/image-20200207231837317.png" alt="image-20200207231837317"></p><ul><li>添加健康检查依赖</li></ul><figure class="highlight xml"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-actuator<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></div></figure><ul><li><p>配置</p><figure class="highlight yml"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">management:</span></span><br><span class="line">  <span class="attr">endpoints:</span></span><br><span class="line">    <span class="attr">web:</span></span><br><span class="line">      <span class="attr">exposure:</span></span><br><span class="line">        <span class="attr">include:</span> <span class="string">'*'</span></span><br></pre></td></tr></table></div></figure></li></ul><ul><li><p>端点</p><p><span class="external-link"><a   href="http://localhost:8080/actuator"  target="_blank" rel="noopener">http://localhost:8080/actuator</a><i class="fa fa-external-link"></i></span> 查看端点</p><p><span class="external-link"><a   href="http://localhost:8080/actuator/health"  target="_blank" rel="noopener">http://localhost:8080/actuator/health</a><i class="fa fa-external-link"></i></span> 健康检查</p><p>添加详情配置,可以检查详细的健康情况</p><figure class="highlight yml"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">management:</span></span><br><span class="line">    <span class="attr">endpoint:</span></span><br><span class="line">      <span class="attr">health:</span></span><br><span class="line">        <span class="attr">show-details:</span> <span class="string">always</span></span><br></pre></td></tr></table></div></figure></li></ul><p><img src="image/image-20200207233909996.png" alt="image-20200207233909996"></p><ul><li><p>简单研究一下健康检查的源码</p><p>以磁盘检查的为例</p><p>健康检查的类都继承了<code>AbstractHealthIndicator</code>抽象类,而<code>AbstractHealthIndicator</code>实现了<code>HealthIndicator</code>接口,所有健康检查实现类都必须实现<code>doHealthCheck(Health.Builder builder)</code>方法</p><p><img src="image/image-20200207235333557.png" alt="image-20200207235333557"></p></li></ul><figure class="highlight java"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DiskSpaceHealthIndicator</span> <span class="keyword">extends</span> <span class="title">AbstractHealthIndicator</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Log logger = LogFactory.getLog(DiskSpaceHealthIndicator<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> File path;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> DataSize threshold;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Create a new &#123;<span class="doctag">@code</span> DiskSpaceHealthIndicator&#125; instance.</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> path the Path used to compute the available disk space</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> threshold the minimum disk space that should be available</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">DiskSpaceHealthIndicator</span><span class="params">(File path, DataSize threshold)</span> </span>&#123;</span><br><span class="line"><span class="keyword">super</span>(<span class="string">"DiskSpace health check failed"</span>);</span><br><span class="line"><span class="keyword">this</span>.path = path;</span><br><span class="line"><span class="keyword">this</span>.threshold = threshold;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">doHealthCheck</span><span class="params">(Health.Builder builder)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">//获取可用的空间字节数</span></span><br><span class="line"><span class="keyword">long</span> diskFreeInBytes = <span class="keyword">this</span>.path.getUsableSpace();</span><br><span class="line">        <span class="comment">//如果可用的字节数大于预留字节数阈值则认为是健康的,设置status为UP</span></span><br><span class="line"><span class="keyword">if</span> (diskFreeInBytes &gt;= <span class="keyword">this</span>.threshold.toBytes()) &#123;</span><br><span class="line">builder.up();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">//否则任务是不健康的,设置status为DOWN</span></span><br><span class="line">logger.warn(LogMessage.format(<span class="string">"Free disk space below threshold. Available: %d bytes (threshold: %s)"</span>,</span><br><span class="line">diskFreeInBytes, <span class="keyword">this</span>.threshold));</span><br><span class="line">builder.down();</span><br><span class="line">&#125;</span><br><span class="line">        <span class="comment">//输出总空间,可用空间和预留阈值</span></span><br><span class="line">builder.withDetail(<span class="string">"total"</span>, <span class="keyword">this</span>.path.getTotalSpace()).withDetail(<span class="string">"free"</span>, diskFreeInBytes)</span><br><span class="line">.withDetail(<span class="string">"threshold"</span>, <span class="keyword">this</span>.threshold.toBytes());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//这个获取可用字节数还是挺好的,直接利用了File提供的方法</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getUsableSpace</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    SecurityManager sm = System.getSecurityManager();</span><br><span class="line">    <span class="keyword">if</span> (sm != <span class="keyword">null</span>) &#123;</span><br><span class="line">        sm.checkPermission(<span class="keyword">new</span> RuntimePermission(<span class="string">"getFileSystemAttributes"</span>));</span><br><span class="line">        sm.checkRead(path);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (isInvalid()) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0L</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//fs是默认的文件系统FileSystem fs = DefaultFileSystem.getFileSystem();</span></span><br><span class="line">    <span class="keyword">return</span> fs.getSpace(<span class="keyword">this</span>, FileSystem.SPACE_USABLE);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure><p>健康检查使用了建造者模式,对于不同的健康指标非常方便,值得学习</p><p><img src="image/image-20200208000623044.png" alt="image-20200208000623044"></p><ul><li><p>整合Consul和SpringCloud的actuator</p><p>修改配置</p><figure class="highlight yml"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">    <span class="attr">cloud:</span></span><br><span class="line">      <span class="attr">consul:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="number">192.168</span><span class="number">.238</span><span class="number">.128</span></span><br><span class="line">        <span class="attr">port:</span> <span class="number">8500</span></span><br><span class="line">        <span class="attr">discovery:</span></span><br><span class="line">          <span class="attr">health-check-path:</span> <span class="string">/actuator/health</span></span><br></pre></td></tr></table></div></figure></li></ul><p>这样启动之后,再检查consul ui就可以发现没有红色的叉了</p><p><img src="image/image-20200208001532048.png" alt="image-20200208001532048"></p><p>其他的健康检查配置</p><p><img src="image/image-20200208001745953.png" alt="image-20200208001745953"></p>        <h3   id="注册课程微服务到Consul" >          <span class="heading-link">注册课程微服务到Consul</span>        </h3>      <ul><li>添加依赖</li></ul><figure class="highlight xml"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-starter-consul-discovery<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-actuator<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></div></figure><ul><li>配置</li></ul><figure class="highlight yml"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">datasource:</span></span><br><span class="line">    <span class="attr">url:</span> <span class="string">jdbc:mysql://192.168.238.128:3306/ms?serverTimezone=GMT%2B8&amp;characterEncoding=utf8&amp;useSSL=false</span></span><br><span class="line">    <span class="attr">hikari:</span></span><br><span class="line">      <span class="attr">username:</span> <span class="string">lrj</span></span><br><span class="line">      <span class="attr">password:</span> <span class="string">lu11221015</span></span><br><span class="line">      <span class="attr">driver-class-name:</span> <span class="string">com.mysql.cj.jdbc.Driver</span></span><br><span class="line"><span class="comment"># JPA配置</span></span><br><span class="line">  <span class="attr">jpa:</span></span><br><span class="line">    <span class="attr">hibernate:</span></span><br><span class="line">      <span class="attr">ddl-auto:</span> <span class="string">update</span></span><br><span class="line">    <span class="attr">show-sql:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">application:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">micro-service-class</span></span><br><span class="line">  <span class="attr">cloud:</span></span><br><span class="line">    <span class="attr">consul:</span></span><br><span class="line">      <span class="attr">host:</span> <span class="number">192.168</span><span class="number">.238</span><span class="number">.128</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">8500</span></span><br><span class="line">      <span class="attr">discovery:</span></span><br><span class="line">        <span class="attr">health-check-path:</span> <span class="string">/actuator/health</span></span><br><span class="line"><span class="comment"># 暴露所有的actuator端点</span></span><br><span class="line"><span class="attr">management:</span></span><br><span class="line">  <span class="attr">endpoints:</span></span><br><span class="line">    <span class="attr">web:</span></span><br><span class="line">      <span class="attr">exposure:</span></span><br><span class="line">        <span class="attr">include:</span> <span class="string">'*'</span></span><br><span class="line">  <span class="comment"># 开启健康检查详细信息</span></span><br><span class="line">  <span class="attr">endpoint:</span></span><br><span class="line">    <span class="attr">health:</span></span><br><span class="line">      <span class="attr">show-details:</span> <span class="string">always</span></span><br><span class="line"><span class="attr">server:</span></span><br><span class="line">  <span class="attr">port:</span> <span class="number">8081</span></span><br></pre></td></tr></table></div></figure><ul><li>重构用户微服务</li></ul><figure class="highlight java"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="meta">@RequestMapping</span>(<span class="string">"user"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserController</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Resource</span></span><br><span class="line">    <span class="keyword">private</span> UserService userService;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Resource</span></span><br><span class="line">    <span class="keyword">private</span> DiscoveryClient discoveryClient;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping</span>(<span class="string">"&#123;id&#125;"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">findUserById</span><span class="params">(@PathVariable(<span class="string">"id"</span>)</span> Integer id) </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> userService.findUserById(id);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping</span>(<span class="string">"discoveryTest"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">discoveryTest</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> discoveryClient.getInstances(<span class="string">"micro-service-class"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure><ul><li>访问端点,可以发现不需要指定课程微服务的主机和端口就可以拿到相关信息,实现了服务发现</li></ul><p><img src="image/image-20200208003543107.png" alt="image-20200208003543107"></p>        <h3   id="重构课程微服务" >          <span class="heading-link">重构课程微服务</span>        </h3>      <ul><li><p>原来</p><figure class="highlight java"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LessonServiceImpl</span> <span class="keyword">implements</span> <span class="title">LessonService</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Resource</span></span><br><span class="line">    <span class="keyword">private</span> LessonRepository lessonRepository;</span><br><span class="line">    <span class="meta">@Resource</span></span><br><span class="line">    <span class="keyword">private</span> LessonUserRepository lessonUserRepository;</span><br><span class="line">    <span class="meta">@Resource</span></span><br><span class="line">    <span class="keyword">private</span> RestTemplate restTemplate;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Lesson <span class="title">buyById</span><span class="params">(Integer id)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 1. 根据课程id查询课程</span></span><br><span class="line">        Lesson lesson = lessonRepository.findById(id).orElseThrow(() -&gt; <span class="keyword">new</span> IllegalArgumentException(<span class="string">"该课程不存在"</span>));</span><br><span class="line">        <span class="comment">//根据课程查询是否已经购买过</span></span><br><span class="line">        LessonUser lessonUser = lessonUserRepository.findByLessonId(id);</span><br><span class="line">        <span class="keyword">if</span> (lessonUser != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> lesson;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//todo 2.登录之后获取userId</span></span><br><span class="line">        String userId = <span class="string">"1"</span>;</span><br><span class="line">        <span class="comment">// 3. 如果没有购买过,查询用户余额</span></span><br><span class="line">        UserDTO userDTO = restTemplate.getForObject(<span class="string">"http://localhost:8080/user/&#123;userId&#125;"</span>, UserDTO<span class="class">.<span class="keyword">class</span>, <span class="title">userId</span>)</span>;</span><br><span class="line">        <span class="keyword">if</span> (userDTO != <span class="keyword">null</span> &amp;&amp; userDTO.getMoney() != <span class="keyword">null</span> &amp;&amp;</span><br><span class="line">                userDTO.getMoney().subtract(lesson.getPrice()).doubleValue() &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"余额不足"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//4. 购买逻辑</span></span><br><span class="line">        <span class="comment">//todo 4.1.调用微服务金额扣减接口 4.2.向lesson_user表插入记录</span></span><br><span class="line">        <span class="keyword">return</span> lesson;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure><p>这个写死了主机地址,无法动态获取微服务路径</p></li><li><p>重构</p><figure class="highlight java"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LessonServiceImpl</span> <span class="keyword">implements</span> <span class="title">LessonService</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Resource</span></span><br><span class="line">    <span class="keyword">private</span> LessonRepository lessonRepository;</span><br><span class="line">    <span class="meta">@Resource</span></span><br><span class="line">    <span class="keyword">private</span> LessonUserRepository lessonUserRepository;</span><br><span class="line">    <span class="meta">@Resource</span></span><br><span class="line">    <span class="keyword">private</span> DiscoveryClient discoveryClient;</span><br><span class="line">    <span class="meta">@Resource</span></span><br><span class="line">    <span class="keyword">private</span> RestTemplate restTemplate;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Lesson <span class="title">buyById</span><span class="params">(Integer id)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 1. 根据课程id查询课程</span></span><br><span class="line">        Lesson lesson = lessonRepository.findById(id).orElseThrow(() -&gt; <span class="keyword">new</span> IllegalArgumentException(<span class="string">"该课程不存在"</span>));</span><br><span class="line">        <span class="comment">//根据课程查询是否已经购买过</span></span><br><span class="line">        LessonUser lessonUser = lessonUserRepository.findByLessonId(id);</span><br><span class="line">        <span class="keyword">if</span> (lessonUser != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> lesson;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//todo 2.登录之后获取userId</span></span><br><span class="line">        String userId = <span class="string">"1"</span>;</span><br><span class="line">        List&lt;ServiceInstance&gt; instances = discoveryClient.getInstances(<span class="string">"micro-service-user"</span>);</span><br><span class="line">        <span class="keyword">if</span> (instances != <span class="keyword">null</span> &amp;&amp; !instances.isEmpty()) &#123;</span><br><span class="line">            <span class="comment">//todo 需要改进,如果存在多个实例,需要考虑负载均衡</span></span><br><span class="line">            ServiceInstance instance = instances.get(<span class="number">0</span>);</span><br><span class="line">            URI uri = instance.getUri();</span><br><span class="line">            UserDTO userDTO = restTemplate.getForObject(uri + <span class="string">"/user/&#123;userId&#125;"</span>, UserDTO<span class="class">.<span class="keyword">class</span>, <span class="title">userId</span>)</span>;</span><br><span class="line">            <span class="keyword">if</span> (userDTO != <span class="keyword">null</span> &amp;&amp; userDTO.getMoney() != <span class="keyword">null</span> &amp;&amp;</span><br><span class="line">                    userDTO.getMoney().subtract(lesson.getPrice()).doubleValue() &lt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"余额不足"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//4. 购买逻辑</span></span><br><span class="line">            <span class="comment">//todo 4.1.调用微服务金额扣减接口 4.2.向lesson_user表插入记录</span></span><br><span class="line">            <span class="keyword">return</span> lesson;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"用户微服务异常,无法购买课程"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure><p>可以动态的获取到用户微服务的地址,请求正常</p><p><img src="image/image-20200208004838563.png" alt="image-20200208004838563"></p></li></ul>        <h3   id="元数据" >          <span class="heading-link">元数据</span>        </h3>      <p>Consul是没有元数据的概念的,所以SpringCloud做了个适配,在consul下设置tags作为元数据.</p><p>元数据可以对微服务添加描述,标识,例如机房在哪里,这样可以进行就近判断,或者当就近机房不可用时才检查远程机房,当两者都不可用时才认为服务不可用等实现容灾或者跨机房</p><ul><li><p>配置</p><figure class="highlight yml"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">cloud:</span></span><br><span class="line">    <span class="attr">consul:</span></span><br><span class="line">      <span class="attr">host:</span> <span class="number">192.168</span><span class="number">.238</span><span class="number">.128</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">8500</span></span><br><span class="line">      <span class="attr">discovery:</span></span><br><span class="line">        <span class="attr">health-check-path:</span> <span class="string">/actuator/health</span></span><br><span class="line">        <span class="attr">tags:</span> <span class="string">JiFang=Beijing,JiFang=Shanghai</span></span><br></pre></td></tr></table></div></figure></li><li><p>实现机房选择</p><figure class="highlight java"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@GetMapping</span>(<span class="string">"discoveryTest"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">discoveryTest</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    List&lt;ServiceInstance&gt; instances = discoveryClient.getInstances(<span class="string">"micro-service-class"</span>);</span><br><span class="line">    <span class="keyword">if</span> (instances != <span class="keyword">null</span>) &#123;</span><br><span class="line">        List&lt;ServiceInstance&gt; shanghaiInstances = instances.stream()</span><br><span class="line">                .filter(s -&gt; s.getMetadata().containsKey(<span class="string">"Shanghai"</span>)).collect(Collectors.toList());</span><br><span class="line">        <span class="keyword">if</span> (!shanghaiInstances.isEmpty()) &#123;</span><br><span class="line">            <span class="keyword">return</span> shanghaiInstances;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> instances;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> SpringCloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringCloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MapReduce教程</title>
      <link href="/2019/04/01/MapReduce%20Tutorial/"/>
      <url>/2019/04/01/MapReduce%20Tutorial/</url>
      
        <content type="html"><![CDATA[        <h1   id="MapReduce-Tutorial" >          <span class="heading-link">MapReduce Tutorial</span>        </h1>              <h2   id="Overview" >          <span class="heading-link">Overview</span>        </h2>      <ul><li>Hadoop MapReduce是一个运行在集群上,并行处理大量数据(TB级别)的框架</li><li>MapReduce任务通常讲输入切分成多个独立的块,这些数据块被独立的map任务并行的处理</li><li>该框架会对map输出进行排序,作为reduce任务的输入</li><li>该框架负责调度任务,监视任务并重新执行失败的任务</li><li>通常,计算的节点和数据存储节点是同一个节点,也就是说,MapReduce框架和HDFS都运行在同一些列节点中.这个约束使得框架在数据已经存在的节点上有效地调度任务,从而产生跨集群的非常高的聚合带宽</li><li>MapReduce框架由一个ResourceManager,集群每个节点的NodeManager和每个应用程序的MRAppMaster组成</li><li>必须指定输入输出路径,实现指定的接口或者抽象类,覆写map和reduce方法</li><li>hadoop任务客户端提交任务和相关配置到ResouceManager,ResouceManager负责把任务/配置分发到其他的从节点,并调度和监控任务,给客户端提供任务的状态和诊断信息</li><li>hadoop stream允许用户使用任何可执行的程序来作为mapper/reducer任务</li><li>hadoop pipes工具可以使用C++ API来实现mapper/reducer</li></ul>        <h2   id="Inputs-and-Outputs" >          <span class="heading-link">Inputs and Outputs</span>        </h2>      <ul><li>MapReduce框架只针对&lt;Key,Value&gt;键值对类型操作.也就是说,每个MapReduce任务的输入是&lt;Key,Value&gt;形式,输入也是&lt;Key,Value&gt;形式,输入输出类型可不相同</li><li>Key,Value的类型必须是可以被框架序列化的类型,因此他们必须实现Writable接口.</li><li>Key的类型除了实现Writable接口之外,还需要实现WritableComparable接口,这样才能被排序</li><li>(input) <code>&lt;k1,v1&gt; -&gt;</code> <strong>map</strong> <code>-&gt; &lt;k2,v2&gt; -&gt;</code> <strong>combine</strong> <code>-&gt;  &lt;k2,v2&gt;  -&gt;</code> <strong>reduce</strong> <code>-&gt; &lt;k3,v3&gt;</code>  (output)</li></ul><p><strong>hadoop jar的一些参数</strong></p><ul><li>-files 可以使用逗号分隔,指定多个文件</li><li>-libjars 可以添加jar包到map和reduce类路径下</li><li>-archives 可以使用逗号分隔传入多个压缩包路径</li></ul>        <h2   id="MapReduce-User-Interfaces" >          <span class="heading-link">MapReduce - User Interfaces</span>        </h2>      <ul><li>实现Mapper和Reducer接口吗,并提供map/reduce的实现是任务的核心</li></ul>        <h4   id="Mapper" >          <span class="heading-link">Mapper</span>        </h4>      <ul><li>Mapper将输入的,Key/Value键值对类型映射成中间结果的Key/Value键值对类型</li><li>Maps是独立的任务,负责将输入转成中间结果</li><li>中间结果的类型无需和输入的类型一样</li><li>一个输入可能对应0,1,或者多个输出</li><li>每个InputSplit(由InputFormat产生)都有一个map任务</li><li>可以通过<span class="external-link"><a   href="https://hadoop.apache.org/docs/r2.8.5/api/org/apache/hadoop/mapreduce/Job.html"  target="_blank" rel="noopener">Job.setMapperClass(Class)</a><i class="fa fa-external-link"></i></span> 来传入Mapper的实现.框架将对每个键值对形式的InputSplit调用<span class="external-link"><a   href="https://hadoop.apache.org/docs/r2.8.5/api/org/apache/hadoop/mapreduce/Mapper.html"  target="_blank" rel="noopener">map(WritableComparable, Writable, Context)</a><i class="fa fa-external-link"></i></span> 方法.如果需要清理一些必要资源,可以覆写<code>cleanup(Context)</code>方法</li><li>map的输出可以通过调用context.write(WritableComparable, Writable)来收集</li><li>所有的中间结果会被框架分组,然后传给Reducer.用户使用 <span class="external-link"><a   href="https://hadoop.apache.org/docs/r2.8.5/api/org/apache/hadoop/mapreduce/Job.html"  target="_blank" rel="noopener">Job.setGroupingComparatorClass(Class)</a><i class="fa fa-external-link"></i></span>指定比较器Comparator来控制分组</li><li>Mapper的输出会被排序(sort)和打散(partitioner)分发给每一个Reducer.partitioner数目和reduce任务的数量相同.用户可以实现Partitioner接口来自定义打散规则,控制不同的Key分到对应的reduce任务中</li><li>用户可以使用<span class="external-link"><a   href="https://hadoop.apache.org/docs/r2.8.5/api/org/apache/hadoop/mapreduce/Job.html"  target="_blank" rel="noopener">Job.setCombinerClass(Class)</a><i class="fa fa-external-link"></i></span>对中间输出结果进行本地聚合,这可以减少从Mapper传到Reduce的传输量</li><li>中间结果都是以简单的 (key-len, key, value-len, value) 形式存储,也可通过Configuration设置对中间结果进行压缩</li></ul>        <h5   id="How-Many-Maps" >          <span class="heading-link">How Many Maps?</span>        </h5>      <ul><li>map任务的通常是由输入数据的大小来决定的,也就是输入文件的块数</li><li>对于cpu轻量级任务来说,每个节点map的并行度可达300,但是一般情况下并行度在10-100之间.任务的启动需要一定的时间,所以map任务至少需要1min的执行时间</li></ul>        <h4   id="Reducer" >          <span class="heading-link">Reducer</span>        </h4>      <ul><li>Reducer将相同key的中间结果集进行处理</li><li>reduce任务的个数是通过<span class="external-link"><a   href="https://hadoop.apache.org/docs/r2.8.5/api/org/apache/hadoop/mapreduce/Job.html"  target="_blank" rel="noopener">Job.setNumReduceTasks(int)</a><i class="fa fa-external-link"></i></span>来设置的</li><li>通过 <span class="external-link"><a   href="https://hadoop.apache.org/docs/r2.8.5/api/org/apache/hadoop/mapreduce/Job.html"  target="_blank" rel="noopener">Job.setReducerClass(Class)</a><i class="fa fa-external-link"></i></span>来设置Reducer的实现类.框架对每组&lt;key, (list of values)&gt;的输入进行调用<span class="external-link"><a   href="https://hadoop.apache.org/docs/r2.8.5/api/org/apache/hadoop/mapreduce/Reducer.html"  target="_blank" rel="noopener">reduce(WritableComparable, Iterable, Context)</a><i class="fa fa-external-link"></i></span> 方法进行处理,需要清理资源可以覆写cleanup(Context)</li></ul>        <h5   id="Shuffle" >          <span class="heading-link">Shuffle</span>        </h5>      <ul><li>传到Reducer的输入是经过排序后的mapper的输出.shuffle阶段,框架将通过http获取相关partition的mapper输出</li></ul>        <h5   id="Sort" >          <span class="heading-link">Sort</span>        </h5>      <ul><li>排序阶段,框架将Reducer的输入进行按Key进行分组</li><li>shuffle和sort同时进行.在map输出被拉取时,他们进行合并</li></ul>        <h5   id="Secondary-Sort" >          <span class="heading-link">Secondary Sort</span>        </h5>      <ul><li>如果中间结果key的分组规则需要和进入reducer前的keys的分组规则不一样,那么可以通过<span class="external-link"><a   href="https://hadoop.apache.org/docs/r2.8.5/api/org/apache/hadoop/mapreduce/Job.html"  target="_blank" rel="noopener">Job.setSortComparatorClass(Class)</a><i class="fa fa-external-link"></i></span>来设置比较器.因为<span class="external-link"><a   href="https://hadoop.apache.org/docs/r2.8.5/api/org/apache/hadoop/mapreduce/Job.html"  target="_blank" rel="noopener">Job.setSortComparatorClass(Class)</a><i class="fa fa-external-link"></i></span>时用来控制中间结果的keys是怎么分组的,所以可以用这个来对值进行二次排序</li></ul>        <h5   id="Reduce" >          <span class="heading-link">Reduce</span>        </h5>      <ul><li>reduce阶段,将对每一组&lt;key, (list of values)&gt;输入调用reduce(WritableComparable, Iterable&lt;Writable&gt;, Context)方法</li><li>reduce任务通过 Context.write(WritableComparable, Writable)将输出结果写入文件系统</li><li>输出结果并不会进行排序</li></ul>        <h5   id="How-Many-Reduces" >          <span class="heading-link">How Many Reduces?</span>        </h5>      <ul><li>比较合理的reduce任务的个数计算公式是:0.95(或1.75)×节点数(注意,不是每个节点的最大container数)</li><li>0.95系数可以使得reduce任务在map任务的输出传输结束后同时开始运行</li><li>1.75系数可以使得计算快的节点在一批reduce任务计算结束之后开始计算第二批 reduce任务,实现负载均衡</li><li>增加reduce的数量虽然会增加负载，但是可以改善负载匀衡，降低任务失败带来的负面影响</li><li>放缩系数要比整数略小是因为要给推测性任务和失败任务预留reduce位置</li></ul>        <h5   id="Reducer-NONE" >          <span class="heading-link">Reducer NONE</span>        </h5>      <ul><li>如果不需要reduce任务,将reduce任务个数设置为0是合法的</li><li>这种情况下,map任务的输出会直接写入文件系统的指定输出路径<span class="external-link"><a   href="https://hadoop.apache.org/docs/r2.8.5/api/org/apache/hadoop/mapreduce/lib/output/FileOutputFormat.html"  target="_blank" rel="noopener">FileOutputFormat.setOutputPath(Job, Path)</a><i class="fa fa-external-link"></i></span>.在写入文件系统前,map的输出是进行排序的</li></ul>        <h4   id="Partitioner" >          <span class="heading-link">Partitioner</span>        </h4>      <ul><li>partitioner控制中间map输出的key的分区</li><li>可以按照key(或者key的一部分)来产生分区,默认是使用hash进行分区</li><li>分区数和reduce任务的个数相等</li><li>控制发送给reduce的任务个数</li></ul>        <h4   id="Counter" >          <span class="heading-link">Counter</span>        </h4>      <ul><li>Counter是一个公共基础工具,用来报告MapReduce应用的统计信息</li><li>Mapper和Reducer实现类都可以使用Counter来报告统计</li></ul>        <h3   id="Job-Configuration" >          <span class="heading-link">Job Configuration</span>        </h3>      <ul><li><p>Job就是MapReduce任务的job配置代表</p></li><li><p>一般MapReduce框架会严格按照Job的配置执行,但是有几种情况例外</p><ul><li>某些配置参数被标记为final类型,所以是修改配置是没法达到目的的,例如1.1比例</li><li>某些配置虽然可以直接配置,但是还需要配合其他的参数一起配置才能生效</li></ul></li><li><p>Job通常会指定Mapper,combiner(有必要的话),Partitioner,Reducer,InputFormat,OutputFormat的实现类</p></li><li><p>输入可以使用下列方式指定输入数据文件集</p><ul><li>(<span class="external-link"><a   href="https://hadoop.apache.org/docs/r2.8.5/api/org/apache/hadoop/mapreduce/lib/input/FileInputFormat.html"  target="_blank" rel="noopener">FileInputFormat.setInputPaths(Job, Path…)</a><i class="fa fa-external-link"></i></span>/ <span class="external-link"><a   href="https://hadoop.apache.org/docs/r2.8.5/api/org/apache/hadoop/mapreduce/lib/input/FileInputFormat.html"  target="_blank" rel="noopener">FileInputFormat.addInputPath(Job, Path)</a><i class="fa fa-external-link"></i></span>)</li><li>(<span class="external-link"><a   href="https://hadoop.apache.org/docs/r2.8.5/api/org/apache/hadoop/mapreduce/lib/input/FileInputFormat.html"  target="_blank" rel="noopener">FileInputFormat.setInputPaths(Job, String…)</a><i class="fa fa-external-link"></i></span>/ <span class="external-link"><a   href="https://hadoop.apache.org/docs/r2.8.5/api/org/apache/hadoop/mapreduce/lib/input/FileInputFormat.html"  target="_blank" rel="noopener">FileInputFormat.addInputPaths(Job, String)</a><i class="fa fa-external-link"></i></span></li></ul></li><li><p>输出可以使用(<span class="external-link"><a   href="https://hadoop.apache.org/docs/r2.8.5/api/org/apache/hadoop/mapreduce/lib/output/FileOutputFormat.html"  target="_blank" rel="noopener">FileOutputFormat.setOutputPath(Path)</a><i class="fa fa-external-link"></i></span>)来指定输出文件集</p></li><li><p>其他配置都是可选的,如Caparator的使用,将文件放置到DistributeCache,是否中间结果或者最终输出结果需要压缩,是否允许推测模式,最大任务重试次数等</p></li><li><p>可以通过<span class="external-link"><a   href="https://hadoop.apache.org/docs/r2.8.5/api/org/apache/hadoop/conf/Configuration.html"  target="_blank" rel="noopener">Configuration.set(String, String)</a><i class="fa fa-external-link"></i></span>/ <span class="external-link"><a   href="https://hadoop.apache.org/docs/r2.8.5/api/org/apache/hadoop/conf/Configuration.html"  target="_blank" rel="noopener">Configuration.get(String)</a><i class="fa fa-external-link"></i></span>来设置和获取任意需要的参数.但是对于大的只读数据集,还是要用DistributedCache</p></li></ul>        <h3   id="Task-Execution-amp-Environment" >          <span class="heading-link">Task Execution &amp; Environment</span>        </h3>      <ul><li>MRAppMaster在独立的JVM中执行每个Mapper/Reducer任务(任务进程级别)</li><li>子任务继承了MRAppMaster的环境.</li><li>用户可以通过 <code>mapreduce.{map|reduce}.java.opts</code> 给子任务添加额外的参数</li><li>运行时非标准类库路径可以通过-Djava.library.path=&lt;&gt;指定</li><li>如果mapreduce.{map|reduce}.java.opts参数配置包含了<em>@taskid@</em>则在运行时被替换成taskId</li><li>显示JVM GC,JVM JMX无密代理(这样可以结合jconsole,查看内存,线程,线程垃圾回收),最大堆内存,添加其他路径到任务java.library.path的例子</li></ul><figure class="highlight xml"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.java.opts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span></span><br><span class="line">  -Xmx512M -Djava.library.path=/home/mycompany/lib -verbose:gc -Xloggc:/tmp/@taskid@.gc</span><br><span class="line">  -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false</span><br><span class="line">  <span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.java.opts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span></span><br><span class="line">  -Xmx1024M -Djava.library.path=/home/mycompany/lib -verbose:gc -Xloggc:/tmp/@taskid@.gc</span><br><span class="line">  -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false</span><br><span class="line">  <span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></div></figure>        <h4   id="Memory-Management" >          <span class="heading-link">Memory Management</span>        </h4>      <ul><li><p>用户可以通过<code>mapreduce.{map|reduce}.memory.mb</code>指定子任务的最大虚拟内存.注意这个设置是进程级别的</p></li><li><p>注意这个参数不要大于-Xmx的参数,否则VM可能会无法启动</p></li><li><p><code>mapreduce.{map|reduce}.java.opt</code>只能配置MRAppMaster的子任务.配置守护线程的需要参考 <span class="external-link"><a   href="https://hadoop.apache.org/docs/r2.8.5/hadoop-project-dist/hadoop-common/ClusterSetup.html#Configuring_Environment_of_Hadoop_Daemons"  target="_blank" rel="noopener">Configuring the Environment of the Hadoop Daemons</a><i class="fa fa-external-link"></i></span></p></li><li><p>map/reduce任务的性能,可能会被并发数,写入磁盘的频率影响.检查文件系统的统计报告,尤其是从map进入reduce的字节数,这参数是非常宝贵的.</p></li></ul>        <h4   id="Map-Parameters" >          <span class="heading-link">Map Parameters</span>        </h4>      <ul><li>map输出的记录会被序列化到缓冲区,元数据存储在统计缓冲区</li><li>当缓冲区或者元数据超过一定的阈值,缓冲区的内容会被排序然后存储和写入磁盘</li><li>如果缓冲区一直是满状态的,map线程将被阻塞</li><li>map结束后,没有写入磁盘的map输出记录继续写入.</li><li>磁盘上所有的map输出文件段会合并成单个文件</li><li>减少写入磁盘的次数,可以减少map的次数,但是加大缓存区会压缩mapper的可用内存</li></ul><div class="table-container"><table><thead><tr><th align="left">Name</th><th align="left">Type</th><th align="left">Description</th></tr></thead><tbody><tr><td align="left">mapreduce.task.io.sort.mb</td><td align="left">int</td><td align="left">序列化和map输出到缓冲区的记录预排序的累计大小,单位为MB</td></tr><tr><td align="left">mapreduce.map.sort.spill.percent</td><td align="left">float</td><td align="left">序列化缓冲区spill阈值比例,超过会将缓冲区内容写入磁盘</td></tr></tbody></table></div><ul><li>spill之后,如果在写入磁盘过程中,map的输出没有超过spill阈值,则会继续收集到spill结束</li><li>如果是spill设置为0.33,在spill到磁盘的过程,缓冲区继续会被map的输出填充,下一次spill的时候再将这期间填充的内容写到磁盘</li><li>如果spill设置为0.66,则不会触发下一次spill.也就是说,spill可以触发,但是不会阻塞</li><li>一条记录大于缓冲区的会先触发spill,而且会被spill到一个单独的文件.无论这条记录有没有定义combiner,它都会被combiner传输</li></ul>        <h4   id="Shuffle-Reduce-Parameters" >          <span class="heading-link">Shuffle/Reduce Parameters</span>        </h4>      <ul><li>reduce将partitioner通过http指派给自己的map输出加载到内存,并定期合并输出到磁盘.</li><li>如果中间结果是压缩输出,那么输出也是被reduce压缩的读进内存中,减少了内存的压力</li></ul><div class="table-container"><table><thead><tr><th align="left">Name</th><th align="left">Type</th><th align="left">Description</th></tr></thead><tbody><tr><td align="left">mapreduce.task.io.soft.factor</td><td align="left">int</td><td align="left">每次合并磁盘上段的数目.如果超过这个设置会分多次进行合并</td></tr><tr><td align="left">mapreduce.reduce.merge.inmem.thresholds</td><td align="left">int</td><td align="left">在合并写入磁盘之前,将排序后的map输出加载到内存的map输出数目.这个值通常设置很大(1000)或者直接禁用(0),因为内存合并要比磁盘合并的代价小得多.这个阈值只影响shuffle期间内存中合并的频率</td></tr><tr><td align="left">mapreduce.reduce.shuffle.merge.percent</td><td align="left">float</td><td align="left">在内存合并之前,读取map输出的内存阈值,代表着用于存储map输出在内存中的百分比.因为map的输出并不适合存储在内存,所以设置很高会知道使得获取和合并的并行度下降.相反,设置为1可以使得内存运行的reduce更快.这个参数只影响shuffle期间的内存内合并频率</td></tr><tr><td align="left">mapreduce.reduce.shuffle.input.buffer.percent</td><td align="left">float</td><td align="left">在shuffle期间,可以分配来存储map输出的内存百分比,相对于<code>mapreduce.reduce.java.opts</code>指定的最大堆内存.把这个值设的大一点可以存储更多的map输出,但是也应该为框架预留一些内存</td></tr><tr><td align="left">mapreduce.reduce.input.buffer.percent</td><td align="left">float</td><td align="left">相当于reduce阶段,用于存储map输出的最大堆内存的内存百分比.reduce开始的时候,map的输出被合并到磁盘,知道map输出在一定的阈值之内.默认情况下,在reduce开始之前,map的输出都会被合并到磁盘,这样才能使得reduce充分的利用到内存.对于只要内存密集型的reduce任务,应该增加这个值,减少磁盘的的往返时间</td></tr></tbody></table></div>        <h4   id="Configured-Parameters" >          <span class="heading-link">Configured Parameters</span>        </h4>      <p>这些参数都是局部的,每个任务的</p><div class="table-container"><table><thead><tr><th align="left">Name</th><th align="left">Type</th><th align="left">Description</th></tr></thead><tbody><tr><td align="left">mapreduce.job.id</td><td align="left">String</td><td align="left">The job id</td></tr><tr><td align="left">mapreduce.job.jar</td><td align="left">String</td><td align="left">job.jar location in job directory</td></tr><tr><td align="left">mapreduce.job.local.dir</td><td align="left">String</td><td align="left">The job specific shared scratch space</td></tr><tr><td align="left">mapreduce.task.id</td><td align="left">String</td><td align="left">The task id</td></tr><tr><td align="left">mapreduce.task.attempt.id</td><td align="left">String</td><td align="left">The task attempt id</td></tr><tr><td align="left">mapreduce.task.is.map</td><td align="left">boolean</td><td align="left">Is this a map task</td></tr><tr><td align="left">mapreduce.task.partition</td><td align="left">int</td><td align="left">The id of the task within the job</td></tr><tr><td align="left">mapreduce.map.input.file</td><td align="left">String</td><td align="left">The filename that the map is reading from</td></tr><tr><td align="left">mapreduce.map.input.start</td><td align="left">long</td><td align="left">The offset of the start of the map input split</td></tr><tr><td align="left">mapreduce.map.input.length</td><td align="left">long</td><td align="left">The number of bytes in the map input split</td></tr><tr><td align="left">mapreduce.task.output.dir</td><td align="left">String</td><td align="left">The task’s temporary output directory</td></tr></tbody></table></div><p>在流任务执行过程中,这些参数会被转化.点(.)会被转成下划线(_),所以要想在流任务的mapper/reducer中获得这些值,需要使用下划线形式.</p>        <h4   id="Distributing-Libraries" >          <span class="heading-link">Distributing Libraries</span>        </h4>      <ul><li><span class="external-link"><a   href="https://hadoop.apache.org/docs/r2.8.5/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html#DistributedCache"  target="_blank" rel="noopener">DistributedCache</a><i class="fa fa-external-link"></i></span>分布式缓存可以分发jars和本地类库给map/reduce任务使用.</li><li>child-jvm总将自己的工作目录添加到java.library.path和LD_LIBRARY_PATH</li><li>缓存中的类库可以通过System.loadLibrary或者System.load</li></ul>        <h3   id="Job-Submission-and-Monitoring" >          <span class="heading-link">Job Submission and Monitoring</span>        </h3>      <ul><li>Job是用户任务和ResourceManager交互的主要接口</li><li>Job的提交流程包括<ul><li>检查输入输出路径</li><li>计算任务的InputSplit</li><li>有必要的话,设置必要的分布式缓存</li><li>拷贝任务的jar和配置到MapReduce系统目录</li><li>提交任务到ResourceManager.监控任务状态是可选的</li><li>任务的执行记录历史存放在 <code>mapreduce.jobhistory.intermediate-done-dir</code> 和<code>mapreduce.jobhistory.done-dir</code></li></ul></li></ul>        <h4   id="Job-Control" >          <span class="heading-link">Job Control</span>        </h4>      <ul><li>对于单个MapReduce任务无法完成的任务,用户可能需要执行MapReduce任务链,才能完成.这还是非常容易的,因为任务的输出一般是存储在分布式文件系统中,所以一个任务的输出可以作为另一个任务的输入.这也就使得判断任务是否完成,不管成功或者失败,都需要用户来控制.主要有两种控制手段<ul><li>Job.submit() 提交任务到集群中,立即返回</li><li>Job.waitForCompletion(boolean) 提交任务到集群中,等待其完成</li></ul></li></ul>        <h3   id="Job-Input" >          <span class="heading-link">Job Input</span>        </h3>      <ul><li><p>InputFormat描述了MapReduce任务的输入规范</p></li><li><p>InputFormat的职责是:</p><ul><li>校验输入是否合法</li><li>将输入逻辑切分成InputSplit实例,之后将它们发送到独立的Mapper</li><li>RecordReader 实现了从符合框架逻辑的InputSplit实例收集输入的记录,提供给Mapper进行处理</li></ul></li><li><p>默认的InputFormat是基于输入文件的总字节大小,将输入文件切分成逻辑的InputSplit实例,例如FileInputFormat的子类.然而,文件系统的blocksize只是split的上限,下限需要通过<code>mapreduce.input.fileinputformat.split.minsize</code>来设置</p></li><li><p>压缩文件并不一定可以被切分,如.gz文件会把完整的文件交给一个mapper来处理</p></li></ul>        <h4   id="InputSplit" >          <span class="heading-link">InputSplit</span>        </h4>      <ul><li><p>InputSplit代表了一个独立Mapper处理的输入数据</p></li><li><p>通常InputSplit是面向字节的,把面向字节转为面向记录是RecordReader的职责</p></li><li><p>FileSplit是默认的InputSplit实现,它把输入设置成mapreduce.map.input.file 属性,用于进行逻辑分割</p></li></ul>        <h4   id="RecordReader" >          <span class="heading-link">RecordReader</span>        </h4>      <ul><li>RecordReader负责将InputSplit的面向字节的输入转换成面向记录,提供给Mapper实现去处理每一条记录.因此RecordReader承担了从记录中提取出键值对的任务</li></ul>        <h3   id="Job-Output" >          <span class="heading-link">Job Output</span>        </h3>      <ul><li>OutputFormat描述了MapReduce输出的规范</li><li>OutputFormat的职责:<ul><li>校验任务的输出,例如输出目录是否存在</li><li>RecordWriter实现可以将任务的输出写入到文件,存储在文件系统中</li></ul></li><li>TextOutputFormat是默认的OutputFormat实现</li></ul>]]></content>
      
      
      <categories>
          
          <category> MapReduce </category>
          
          <category> Hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop,MapReduce </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hive的一些坑</title>
      <link href="/2019/04/01/hive%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9D%91/"/>
      <url>/2019/04/01/hive%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9D%91/</url>
      
        <content type="html"><![CDATA[        <h1   id="Hive的一些坑" >          <span class="heading-link">Hive的一些坑</span>        </h1>      <ol><li>specified datastore driver(“com.mysql.jdbc.Driver”) was not found</li></ol><p><img src="image/image-20200126114217615.png" alt="image-20200126114217615"></p><p>这个是因为驱动不对,下载了个新的就行了</p><ol start="2"><li>Unable to open a test connection to the given database. JDBC url = jdbc:mysql://hadoop001:3306/test?useSSL=true&amp;serverTimezone=GMT%2B8, username = lrj. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception:</li></ol><p><img src="image/image-20200126114500594.png" alt="image-20200126114500594"></p><p>这个需要把ssl禁用了,在jdbcUrl上指定useSSL=false</p><ol start="3"><li>MetaException(message:Version information not found in metastore. )</li></ol><p><img src="image/image-20200126114708126.png" alt="image-20200126114708126"></p><p>这个需要将hive-site.xml中的hive.metastore.schema.verification设置为false</p><ol start="4"><li>Required table missing : “<code>VERSION</code>“ in Catalog “” Schema “”. DataNucleus requires this table to perform its persistence operations. Either your MetaData is incorrect, or you need to enable “datanucleus.autoCreateTables”</li></ol><p><img src="image/image-20200126114930654.png" alt="image-20200126114930654"></p><p>这个需要初始化一下schema,执行</p><p>schematool -dbType mysql -initSchema</p><hr><p>之后就可以启动metastore + hiveserver2服务</p><figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nohup hive --service  metastore &gt; ~/metastore.log 2&gt;&amp;1 &amp;</span><br><span class="line">nohup  hiveserver2  &gt; ~/hiveserver2.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></div></figure><p>测试hiveserver2服务是否ok</p><figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">beeline</span><br></pre></td></tr></table></div></figure><p>打印日志</p><figure class="highlight plain"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">which: no hbase in (&#x2F;usr&#x2F;local&#x2F;bin:&#x2F;usr&#x2F;bin:&#x2F;usr&#x2F;local&#x2F;sbin:&#x2F;usr&#x2F;sbin:&#x2F;mysql&#x2F;bin:&#x2F;home&#x2F;lurongjiang&#x2F;.local&#x2F;bin:&#x2F;home&#x2F;lurongjiang&#x2F;bin:&#x2F;usr&#x2F;software&#x2F;hadoop-2.6.0-cdh5.16.2&#x2F;bin:&#x2F;usr&#x2F;software&#x2F;hadoop-2.6.0-cdh5.16.2&#x2F;sbin:&#x2F;usr&#x2F;software&#x2F;jdk1.8.0_231&#x2F;bin:&#x2F;usr&#x2F;software&#x2F;apache-maven-3.6.3&#x2F;bin:&#x2F;usr&#x2F;software&#x2F;scala-2.11.12&#x2F;bin:&#x2F;usr&#x2F;software&#x2F;hive-1.1.0-cdh5.16.2&#x2F;bin)</span><br><span class="line">Beeline version 1.1.0-cdh5.16.2 by Apache Hive</span><br><span class="line"># 查看下数据库,此时发现没连接</span><br><span class="line">beeline&gt; show databases;</span><br><span class="line">No current connection</span><br><span class="line"># 尝试连接数据库,只需要输入用户名就行,不需要密码</span><br><span class="line">beeline&gt; !connect jdbc:hive2:&#x2F;&#x2F;hadoop001:10000&#x2F;default</span><br><span class="line">Connecting to jdbc:hive2:&#x2F;&#x2F;hadoop001:10000&#x2F;default</span><br><span class="line">Enter username for jdbc:hive2:&#x2F;&#x2F;hadoop001:10000&#x2F;default: lrj</span><br><span class="line">Enter password for jdbc:hive2:&#x2F;&#x2F;hadoop001:10000&#x2F;default: </span><br><span class="line">Error: Failed to open new session: java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.security.AccessControlException: Permission denied: user&#x3D;lrj, access&#x3D;EXECUTE, inode&#x3D;&quot;&#x2F;tmp&quot;:lurongjiang:supergroup:drwx</span><br></pre></td></tr></table></div></figure><ol start="5"><li>java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.security.AccessControlException: Permission denied: user=lrj, access=EXECUTE, inode=”/tmp”:lurongjiang:supergroup:drwx——</li></ol><p><img src="image/image-20200126115801228.png" alt="image-20200126115801228"></p><p> 这个是没权限</p><p>hadoop fs -chmod -R 777  /tmp</p><p>再次启动就ok了.</p>]]></content>
      
      
      <categories>
          
          <category> Hive </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hive </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hive UDF</title>
      <link href="/2019/03/15/Hive%20UDF/"/>
      <url>/2019/03/15/Hive%20UDF/</url>
      
        <content type="html"><![CDATA[        <h1   id="Hive-UDF" >          <span class="heading-link">Hive UDF</span>        </h1>      <p>hive内置函数并不一定满足我们的业务要求,所以需要拓展,即用户自定义函数</p><p><strong>UDF</strong></p><p>User Defined Function</p><ul><li>UDF (one-to-one)</li><li>UDAF(many-to-one)</li><li>UDTF(one-to-many)</li></ul>        <h2   id="创建UDF步骤" >          <span class="heading-link">创建UDF步骤</span>        </h2>      <ul><li><p>添加依赖</p><figure class="highlight xml"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hive<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hive-exec<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hive.cdh.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></div></figure></li></ul><ul><li>创建自定义类,继承UDF</li></ul>]]></content>
      
      
      <categories>
          
          <category> Hive </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hive </tag>
            
            <tag> udf </tag>
            
            <tag> user-defined-function </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop MapReduce编程核心</title>
      <link href="/2019/03/12/Hadoop%20MapReduce%E7%BC%96%E7%A8%8B%E6%A0%B8%E5%BF%83/"/>
      <url>/2019/03/12/Hadoop%20MapReduce%E7%BC%96%E7%A8%8B%E6%A0%B8%E5%BF%83/</url>
      
        <content type="html"><![CDATA[        <h1   id="Hadoop-MapReduce编程核心" >          <span class="heading-link">Hadoop MapReduce编程核心</span>        </h1>              <h2   id="Partitioner-分区" >          <span class="heading-link">Partitioner 分区</span>        </h2>      <figure class="highlight java"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * Partitions the key space.</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * &lt;p&gt;&lt;code&gt;Partitioner&lt;/code&gt; controls the partitioning of the keys of the </span></span><br><span class="line"><span class="comment"> * intermediate map-outputs. The key (or a subset of the key) is used to derive</span></span><br><span class="line"><span class="comment"> * the partition, typically by a hash function. The total number of partitions</span></span><br><span class="line"><span class="comment"> * is the same as the number of reduce tasks for the job. Hence this controls</span></span><br><span class="line"><span class="comment"> * which of the &lt;code&gt;m&lt;/code&gt; reduce tasks the intermediate key (and hence the </span></span><br><span class="line"><span class="comment"> * record) is sent for reduction.&lt;/p&gt;</span></span><br><span class="line"><span class="comment"> * partitioner是控制中间map阶段输出结果的key的分区.key通常被hash,分发到各个分区</span></span><br><span class="line"><span class="comment"> * 分区数一般和reduce job的个数相等,</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@see</span> Reducer</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@InterfaceAudience</span>.Public</span><br><span class="line"><span class="meta">@InterfaceStability</span>.Stable</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Partitioner</span>&lt;<span class="title">K2</span>, <span class="title">V2</span>&gt; <span class="keyword">extends</span> <span class="title">JobConfigurable</span> </span>&#123;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">/** </span></span><br><span class="line"><span class="comment">   * Get the paritition number for a given key (hence record) given the total </span></span><br><span class="line"><span class="comment">   * number of partitions i.e. number of reduce-tasks for the job.</span></span><br><span class="line"><span class="comment">   * </span></span><br><span class="line"><span class="comment">   * &lt;p&gt;Typically a hash function on a all or a subset of the key.&lt;/p&gt;</span></span><br><span class="line"><span class="comment">   * 根据分区总数,例如reduce job个数,获取分区的编号.一般是对所有key或者key的一部分进行进行hash处理</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> key the key to be paritioned.</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> value the entry value.</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> numPartitions the total number of partitions.</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@return</span> the partition number for the &lt;code&gt;key&lt;/code&gt;.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">int</span> <span class="title">getPartition</span><span class="params">(K2 key, V2 value, <span class="keyword">int</span> numPartitions)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* hash分区的实现就是key取hashCode和reduce个数进行取模</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HashPartitioner</span>&lt;<span class="title">K2</span>, <span class="title">V2</span>&gt; <span class="keyword">implements</span> <span class="title">Partitioner</span>&lt;<span class="title">K2</span>, <span class="title">V2</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(JobConf job)</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Use &#123;<span class="doctag">@link</span> Object#hashCode()&#125; to partition. */</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getPartition</span><span class="params">(K2 key, V2 value,</span></span></span><br><span class="line"><span class="function"><span class="params">                          <span class="keyword">int</span> numReduceTasks)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> (key.hashCode() &amp; Integer.MAX_VALUE) % numReduceTasks;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure><blockquote><p> <strong>需要注意的是</strong></p><ul><li>分区数一般和reduce job个数相等</li><li>如果分区数&lt;reduce job个数,将导致输出有很多无用的空文件</li><li>如果分区数&gt;reduce job个数,将导致有些map输出找不到hash路径,出现java.io.IOException: Illegal partition for xxx的异常</li></ul></blockquote>        <h2   id="Combiner-局部汇总" >          <span class="heading-link">Combiner 局部汇总</span>        </h2>      <p>Combiner是hadoop对map阶段输出结果进行本地局部聚合,提高后面reduce的效率,避免大量数据进行网络传输.</p><blockquote><p><strong>需要注意的是</strong></p><ul><li>并非所有的任务都适用于Combiner</li><li>求和等操作,局部聚合可以有效的提高后面reduce的效率</li><li>平均值等操作,这种并不适用,因为局部平均值和全局平均值还是有差异的</li></ul></blockquote>]]></content>
      
      
      <categories>
          
          <category> Hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> MapReduce </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2018/07/18/hello-world/"/>
      <url>/2018/07/18/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <span class="external-link"><a   href="https://hexo.io/"  target="_blank" rel="noopener">Hexo</a><i class="fa fa-external-link"></i></span>! This is your very first post. Check <span class="external-link"><a   href="https://hexo.io/docs/"  target="_blank" rel="noopener">documentation</a><i class="fa fa-external-link"></i></span> for more info. If you get any problems when using Hexo, you can find the answer in <span class="external-link"><a   href="https://hexo.io/docs/troubleshooting.html"  target="_blank" rel="noopener">troubleshooting</a><i class="fa fa-external-link"></i></span> or you can ask me on <span class="external-link"><a   href="https://github.com/hexojs/hexo/issues"  target="_blank" rel="noopener">GitHub</a><i class="fa fa-external-link"></i></span>.</p>        <h2   id="Quick-Start" >          <span class="heading-link">Quick Start</span>        </h2>              <h3   id="Create-a-new-post" >          <span class="heading-link">Create a new post</span>        </h3>      <figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></div></figure><p>More info: <span class="external-link"><a   href="https://hexo.io/docs/writing.html"  target="_blank" rel="noopener">Writing</a><i class="fa fa-external-link"></i></span></p>        <h3   id="Run-server" >          <span class="heading-link">Run server</span>        </h3>      <figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></div></figure><p>More info: <span class="external-link"><a   href="https://hexo.io/docs/server.html"  target="_blank" rel="noopener">Server</a><i class="fa fa-external-link"></i></span></p>        <h3   id="Generate-static-files" >          <span class="heading-link">Generate static files</span>        </h3>      <figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></div></figure><p>More info: <span class="external-link"><a   href="https://hexo.io/docs/generating.html"  target="_blank" rel="noopener">Generating</a><i class="fa fa-external-link"></i></span></p>        <h3   id="Deploy-to-remote-sites" >          <span class="heading-link">Deploy to remote sites</span>        </h3>      <figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></div></figure><p>More info: <span class="external-link"><a   href="https://hexo.io/docs/one-command-deployment.html"  target="_blank" rel="noopener">Deployment</a><i class="fa fa-external-link"></i></span></p>]]></content>
      
      
      <categories>
          
          <category> TestNest </category>
          
          <category> test1 </category>
          
          <category> nest1 </category>
          
          <category> nest2 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PlayStation </tag>
            
            <tag> Games </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
